%% Introduction: Length: 25-30 pages.
%%  * Relevant background, 
%%  * Outline of state of knowledge, 
%%  * emphasize outstanding questions 

\chapter{Introduction}

Given the constantly improving cost and speed of genome sequencing, it is reasonable to expect that within the coming decades personal genomes will be known for a substantial part of the global populace. Unfortunately, our limited ability to interpret the variation found within them stands in stark contrast with this development. Even when limiting ourselves to mutations in coding regions of the genome, the effects of most missense variants are not known. While a number of computational approaches exist to make predictions as the effects of coding variants, they are currently not reliable enough for clinical use. Laboratory assays by comparison produce more trustworthy results, but until recently did not scale to the space of all possible mutations. The development of Deep mutational scanning\cite{Fowler2010} has now made this endeavour possible. In the following sections, each of these issues will be discussed in detail.

\section{The Genotype-Phenotype Problem}

Linking genotype to phenotype is a very difficult problem. The part of the human genome we understand best are protein-coding genes, yet they only constitute a minuscule fraction the whole. Impacts of mutations in other functional elements such as introns, untranslated regions of genes, or regulatory sequences, are more difficult to assay, not to mention the vast stretches of intragenic space. While one might expect the latter to not bear functional significance a priori, its importance is nonetheless highlighted by the the fact that a large number of loci identified as correlated with diseases in genome-wide association studies (GWAS) are found within these regions\cite{TODO}.
But even for protein-coding sequences the problem is far from simple. Alleles that behave according to the Mendelian model are the exception. Most phenotypes are complex, i.e. emerge through the interplay of many different genetic or environmental factors. Conversely, many genes are also pleiotropic, i.e. they are involved more than one mechanism. Thus, a mutation found in one person may not have the same effect as in another---a phenomenon called incomplete penetrance. Similarly, two different mutations within the same coding sequence need not have the same effect either. Depending on how the translated protein is affected (catastrophic folding failure, alteration of a molecular interaction interface or active site, or a subtle change on an unused surface) the effects may differ in severity or in rare cases even in the emergence of new behaviours.

Given the much greater difficulty of interpreting non-coding regions, clinical applications have so far largely concentrated on protein-coding genes. Sequencing panels for known disease-associated genes and even whole-exome sequencing (WES) are widely commercially available. A number of different standards for classifying mutations with respect to their potential health impacts have been proposed. Most prominently, the American College of Medical Genetics and Genomics (ACMG) standard\cite{?}. It defines categories stretching from ``pathogenic'' via ``variant of uncertain significance'' (VUS) to ``benign''. Even though the mutational landscape for a handful of genes, such as \gene{BRCA1} are explored better than others due to their high monetization potential\cite{BRCA_Clinic}, the vast majority of clinical variants are currently classified as VUS. For example, over 98\% of missense variants for a gene panel assessing germline cancer risk variants~\cite{Maxwell2016} have been discarded as VUS. Not only can these uncertainties unduly burden patients with unnecessary anxiety, they also call into question the value of sequencing in the clinic if the majority of findings are not actionable. With increasing use of WES, this problem is only going to get worse. According to  the 1000 Genomes Project data, every person carries 100-400 missense variants that are so rare that they have likely never been seen before in the clinic~\cite{1000genomes}. In the absence of previous observations they would automatically be added to long list of VUS.

\section{\textit{In silico} approaches to variant function assessment}

A number of algorithms exist that offer predictions as to the deleteriousness of mutations, the most prominent ones being PolyPhen-2\cite{Polyphen}, SIFT\cite{SIFT} and PROVEAN\cite{PROVEAN}. PolyPhen-2 uses a machine learning method using evolutionary conservation and protein structural features. It uses a set of previously reported pathogenic alleles as a positive training set and differences between human genes and their mammalian homologues as a negative training set. SIFT (Sorting Intolerant From Tolerant) by contrast only uses evolutionary conservation. The tool uses multiple sequence alignments to calculate position-specific score matrices for each gene which are then normalized and transformed into probability values. PROVEAN (PROtein Variation Effect ANalyzer) similarly only takes into account sequence alignments. However, rather than just computing a position-specific score, PROVEAN calculates the difference in alignment quality between using the wildtype or variant sequence against clusters of homologous sequences. The average distance is then interpreted as indicative of the deleteriousness of the variant. 

While the three tools succeed in making good predictions, their reliability is unfortunately still not high enough to serve as a basis of clinical decision making. Song Sun recently performed an independent comparison of these tools on a set of well established disease-causing variants as well as rare polymorphisms with no known disease association\cite{SunExtendedSet}. A high precision (the fraction of correct classifications out of all positive classifications) can be considered especially important when considering taking clinical action based on a prediction. When compared at a minimum precision level of 90\%, PolyPhen-2 and PROVEAN only reach a sensitivity of 19\% and 21\% , respectively (where sensitivity is defined as the fraction of correct classifications out of all real existing disease variants). SIFT was not even capable of achieving 90\% precision at any score threshold.

\section{Functional Complementation}

\section{Binary Protein-Protein interactions and Yeast-2-Hybrid}

\section{Deep Mutational Scanning}

\section{Edgotyping}

\section{Background: The Sumoylation Pathway}