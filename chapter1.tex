

\chapter[A comprehensive high-fidelity DMS framework]{A framework for comprehensive and high-fidelity Deep Mutational Scanning}
\label{ch:data1}

\section{Introduction}

% \todo{Cast this introduction more in the light of functional assays and less about disease. (Save that for the next chapter.)}

Deep Mutational Scanning~(DMS)~\cite{fowler_high-resolution_2010}, a strategy for large-scale functional testing of variants, yields functional maps describing a large fraction of substitutions for an often substantial subset of residue positions. The assays used for DMS studies are diverse, often measuring different aspects of a protein's behaviour. Functional complementation assays test a variant's impact on overall protein function by testing the variant gene's ability to rescue the phenotype caused by reduced activity of the wild type gene (or its ortholog in the case of trans-species complementation)~\cite{lee_complementation_1987,osborn_rescuing_2007}. In a previous paper, Song Sun and other members of the Roth Lab have previously found cell-based functional complementation assays to accurately identify disease variants across a diverse collection of human disease genes~\cite{sun_extended_2016}. 

There are many challenges to the DMS strategy.  One challenge is establishment of robust interpretable assays that measure each variant's impact on the disease-relevant functions of a gene. Another is that the fraction of possible amino acid changes that are measured varies from map to map. Finally, many maps do not control for the overall quality of measurements, or estimate the quality of each measurement. The lack of a comprehensively measured map of known-quality functional impact scores limits the opportunity for confident use of DMS maps to evaluate specific variants.

Here we describe a modular DMS framework to generate  complete, high-fidelity maps of variant function based on functional complementation. The framework employs a novel mutagenesis strategy, two alternative sequencing-based selection screens, and a machine learning strategy to impute  otherwise missing parts of the map with surprising accuracy, and uses regularization to correct less confidently measured data points. We evaluate our framework on the SUMO E2 conjugase \gene{UBE2I}.


\section{Results}

To carry out deep mutational scans of protein sequences yielding comprehensive atlases of sequence-function relationships, we found it useful to organize the process into six stages (see Figure~\ref{fig:framework}): 1) mutagenesis; 2) generation of a clone library; 3) selection for clones encoding a functional protein; 4) read-out of the selection results and analysis to produce an initial sequence-function map; 5) computational analysis to impute missing values; and 6) computational analysis to refine measured values based on imputation models. This framework incorporates previously-described deep mutational scanning concepts as well as new experimental components (e.g. our imputation and regularization strategy) and analytic methods.  The last two stages enabling a complete and accurate DMS map have not been applied in any published DMS study.

We first describe a version of the framework called DMS-BarSeq and apply it to the human SUMO conjugase \gene{UBE2I}, exhaustively measuring the ability of protein variants to function. DMS-BarSeq provides direct variant function measurements and the ability to examine higher-order multi-mutant effects. An alternative version of the framework, DMS-TileSeq, generally captures only single-variant effects, but is less resource-intensive. After comparing DMS-TileSeq and DMS-BarSeq results, we combine these maps, computationally infer missing data points and refine map quality.


\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{img/framework_flowchart.pdf}
	\caption{An overview of the Deep Mutational Scanning Framework. Step 1: Using mutagenesis via POPCode and oxidized nucleotide PCR, a pool of variant ORFs is created. Step 2: A library is generated via en-masse gateway cloning. Depending on the downstream sequencing procedure either plain or barcoded expression vectors are used. Step 3: Clones compete with each other for growth under selective and control conditions. Step 4: In case of BarSeq, barcodes are sequenced and counted. In case of TileSeq, individual tiles within the ORF are amplified used in paired-end sequencing. Step 5: Machine Learning methods are used to impute the effects of missing variants. Step 6: Machine learning predictions are also used to support less confidently measured variants. }
	\label{fig:framework}
\end{figure}


\subsection{A barcode-based Deep Mutational Scanning strategy}

%Describe goals for this screen, and then how the different choices below aim to achieve these.

As an initial test of the overall framework, we first aimed to generate a map of functional missense variation for \gene{UBE2I}. Our goals for this map were as follows: (i) High and even coverage of the full spectrum of amino acid changes; (ii) Determination of mutant effects on overall protein functionality; (iii) High fidelity of functional effect readouts. We therefore designed the different stages of the framework accordingly. 

For Stage 1 of the DMS-BarSeq framework---mutagenesis--- to achieve a relatively even representation of all possible single amino acid substitutions, we wished to allow multiple mutations per clone. This would not only allow for greater mutational coverage for any given library size, but it would also offer an opportunity to discover intragenic epistatic relationships between variants.  To fulfill these requirements, we developed a mutagenesis protocol (Precision Oligo-Pool based Code Alteration or POPCode) which generates random codon replacements. 
At the second stage---library generation---we wished to be able to track the fitness effects of each individual mutant clone rather than just average effects of mutations across the population, as this could be expected to allow for higher quality measurements. Thus, in Stage 2 of the framework, we opted to assign molecular barcodes to each clone that could be identified by sequencing. To catalogue the pairing of mutant genotypes with barcodes, we developed a novel multiplex amplicon sequencing method called KiloSeq, in collaboration with SeqWell Inc, Boston. 
The selection process (Stage 3) was performed as a yeast complementation assay, to allow for determination of overall functional effects of mutations. The assay would be performed as a time series in triplicates, as this again promised to allow for higher quality of readouts 
Finally, Stage 4, consists of barcode sequencing and statistical analysis. All four stages will be described in further detail in the following subsections.


\subsubsection{POPCode: A Precision Oligo Pool Codon alteration mutagenesis method}

This method scales up a previously described method developed by Seyfang~\etal~\cite{seyfang_multiple_2004}. To achieve complete wide coverage over the complete spectrum of possible amino acid changes we design oligonucleotides centering on each codon in the Open Reading Frame (ORF) of interest and replacing the target with an \texttt{NNK} degeneracy code. As explained in chapter~1 section~\ref{dmsIntro}, this has been previously used to allow all amino acid changes while reducing the chance of generating stop codons~\cite{pal_methods_2005}. 
In the next step, the ORF sequence is PCR amplified in the presence of dUTP to generate uracil-doped template for the mutagenesis reaction. Oligonucleotide pools were then hybridized with the template. Gaps between hybridizations were filled with non-strand-displacing polymerase. 

When finding a set of suitable oligonucleotide sequences, two important criteria need to be considered: 
(i) The melting temperature across the complete set is as uniform as possible as this will ensure a more even mutation rate across the ORF sequence; (ii) the degenerate codon sequence should be located as close to the center of the oligo as permissible given the first criterium. To simplify the process of choosing an appropriate set of oligos based on these criteria, I developed a web tool that can be used to calculate the optimal solution to the given problem. The tool requires the sequence of the target ORF and flanking vector sequences, a desired average oligo length and a maximum offset parameter. The offset parameter determines how many bases can be maximally added or removed from each side of a given oligo to optimize its melting temperature. 

In some cases a moderate deviation from the average in melting temperature for some oligos cannot be avoided. To alleviate these effects, the web tool also offers a mutation rate prediction. This is based on observations from all the POPCode procedures performed as part of this work in combination with linear regression. The prediction can be used to preemptivly adjust concentrations of potentially troublesome oligos in the POPCode protocol. An additional web tool feature based on the mutation rate prediction is the automatic calculation of necessary library size to achieve a desired mutational coverage. The web tool as available at \verb|http://llama.mshri.on.ca/cgi/popcodeSuite/main|.

%%Figure: PopCode schema

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{img/popcode_schema.pdf}%TODO: should be direct BP-LR cloning
	\caption{POPCode mutagenesis and library generation. A pool of codon-denerate oligos is hybridized to a uracil-doped template, gaps between oligos are closed via non-strand-displacing polymerase, and the backbone sealed. Uracil-doped template is degraded to enrich for mutants. After mutagenesis, Gateway attB sites are added, followed by BP+LR cloning into barcoded vectors and transformation into bacteria. Finally, colonies are picked and arrayed.}
	\label{fig:popcode_schema}
\end{figure}
Following cleanup, the uracil-doped template was incapacitated using Uracil-DNA-Glycosylase (UDG). The mutagenesis product was then amplified with primers that added attB sites to allow Gateway BP cloning into entry vectors.

To accomplish mutagenesis across the entire coding region of our gene of interest, \gene{UBE2I}, we designed a tiled collection of oligos (one per codon) and applied POPCode to generate a codon-mutagenized amplicon library.  In parallel, we carried out PCR with oxidized nucleotides~\cite{mohan_pcr_2011} to enable deeper representation of amino acid changes achievable from single-nucleotide changes.

\subsubsection{Library generation and highly multiplexed amiplicon sequencing}

For Stage 2 of the framework---generation of a clone library---we employed an \textit{en masse} recombinational cloning strategy to generate a Gateway Entry vector library of \gene{UBE2I} variants. This library was transferred via \textit{en~masse} recombinational subcloning into a pool of randomly-barcoded plasmids enabling expression of \gene{UBE2I} variants in yeast. As sequencing is required to establish the full-length ORF sequence and barcode of each clone, the complementation vector is designed such that the variant ORF and the barcode locus are in close proximity to each other. Thus, only a relatively small segment of the plasmid needs to be inspected to determine the pairing of genotype and barcode. 

After bacterial transformation, we proceeded to robotically pick 19,968 colonies, which were stored in 52 384-well plates. As sequencing needs to be performed to catalogue the identities of nearly 20,000 individual samples, we used a novel sequencing method called KiloSeq which combines plate-position-specific index sequences with Illumina sequencing (Figure~\ref{fig:kiloseq_schema}).
KiloSeq was developed in collaboration with SeqWell Inc., Boston. First, for each clone in the library, the region of interest is amplified with primers containing well-specific tags, uniquely identifying each well coordinate. This step is dependent on the use of a HydroCycler, which allows up to 4608 PCR reactions to be performed in parallel. In the next step, wells for each plate can be pooled. Nextera tagmentation using Tn5 transposase is used to break the amplicons into random fragments and simultaneously ligate them to Illumina sequencing linkers with plate-specific indices. We then re-amplify the pool with  3'-specific primers, to enrich for fragments that contain the well tags. The resulting library is now ready for paired-end sequencing. In each pair of reads, one read will contain the well tag and the barcode locus, whereas the other will contain a fragment of the mutant ORF.
%TODO: move to methods: This is done using a hydrocycler, allowing for thousands of PCR reactions to be performed in parallel. ----- Amplicons can then be plate-wise pooled.

\begin{figure}[h!]
	\centering
	\includegraphics[width=.5\textwidth]{img/kiloseq_schema_new.pdf}
	\caption{KiloSeq schema. 1) For each library well, amplicons containing the variant ORF (gold) and Barcode locus (green) are amplified with primers adding a well-specific tag. 2) Tn5 tagmentation fragments the DNA while simultaneously adding Illumina i5/i7 linkers. 3' re-amplification enriches for fragments containing the well tags. 3) Each pair of sequencing reads now contains a fragment of ORF sequence and the associated barcode and well tag.}
	\label{fig:kiloseq_schema}
\end{figure}

To process the results of a KiloSeq sequencing run, a special software pipeline was developed, which can be divided into three phases: demultiplexing; barcode clustering; and alignment and variant calling.
The first phase---demultiplexing---takes place on two levels, corresponding to library plates and the wells within those plates. Demultiplexing at plate level is performed by Illumina's bcl2fastq software, which resolves i5-i7 index combinations. The second phase is performed on a high performance computing cluster. Sets of read pairs are distributed across computing nodes, where they are processed by worker scripts. The well-tag within each R2 read is identified using a k-mer search algorithm, and read-pairs are sorted accordingly into bins. Each bin corresponds to one well in a given plate. At the same time, barcode sequences are extracted from the R2 reads in preparation for the next phase. 

The second phase---barcode clustering---uses the extracted barcode sequences within each bin and clusters them according to their Levenstein distance~\cite{levenshtein_binary_1966} (i.e. the number of edit operations required to transform one into the other). This step is necessary in order to resolve possible contamination across wells that occurred during library preparation. Each barcode cluster corresponds to a different clone, and the different unique sequences within each clusters correspond to different sequencing errors. The most frequently observed sequence within each cluster is interpreted as the true barcode. Finally, read pairs within each bin are again subdivided according to their respective barcode cluster.

The third phase---alignment and variant calling---is then executed for each barcode cluster within each well within each plate. The R1 reads are aligned to the template sequence and variants are called. This is complicated by the fact that the KiloSeq library preparation usually creates a certain amount of cross-contamination between wells. While single or multi-nucleotide variants are still relatively unproblematic to identify, standard tools were found to be unable to identify copy number variations (CNVs) due to these problems. We thus developed a custom method for CNV calling, based on detecting sudden changes in read depth across the alignments. First the individual read depth track is normalized to the average read depth across the plate. Then a modified one-dimensional Sobel operator~\cite{sobel_3x3_1968} is used to detect sharp edges in the signal. An example of this can be seen in Figure~\ref{fig:border_detect}. Detection thresholds were optimized by comparison with Sanger sequencing.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{img/border_detect.pdf}
	\caption{Indel detection example. A duplication event in well \texttt{A\_A02} is detected by normalizing relative read depth by the mean depth across the plate and using a Sobel operator to detect sudden changes.}
	\label{fig:border_detect}
\end{figure}


After successful genotyping with kiloseq, we determined the subset of clones that (i) contained at least one missense mutation, (ii) did not contain any insertions or deletions, (iii) did not contain mutations outside of the ORF, (iii) had unique barcodes, (iv) had sufficient read coverage during KiloSeq to allow for confident genotyping.
Over half of clones in the library conformed to these criteria. The single largest reason for exclusion was the occurrence of indels and CNVs (Figure~\ref{fig:popcode_census}A). 

\begin{landscape}
\begin{figure}[h]
	\centering
	\includegraphics[width=9in]{img/popcode_census.pdf}
	\caption{KiloSeq-based census of the \gene{UBE2I} POPCode library. A) Breakdown of KiloSeq results for a set of five 384 well plates of mutant clones generated by POPCode. Corrupt: Clones containing mutations outside of the ORF; Frameshift: Clones containing indels or copy number variants; Stop: Clones containing stop codons. B) Breakdown of mutations in codons. Top: Single nucleotide variants; Bottom: Multi-nucleotide variants. Columns correspond to the first, second and third position in a codon. C) Relative shares of single, double and triple nucleotide variants among all missense variants in the library. D) Coverage map of missense variants in the library. Light green track: Coverage across all possible amino acids; Dark green track: Coverage across amino acids reachable with a single nucleotide change from the wildtype codon.}
	\label{fig:popcode_census}
\end{figure}
\end{landscape}

An analysis of the mutation signatures across clones generated by POPCode revealed that two different mechanisms appear to underly mutagenesis. When considering only mutations that change more than one base in a given codon, there is an equal chance for every possible base except in the third position, where almost no adenine or cytosine was introduced. This is consistent with the \texttt{NNK} degeneracy code used in the POPCode oligo design. By contrast, variants that change only a single base in a given codon show a strong bias for transitions over transversions. These could be introduced due to polymerase error (Figure~\ref{fig:popcode_census}B). This secondary source of variation is also reflected in the relative share of single nucleotide variants, which make up 56\% of mutations (Figure~\ref{fig:popcode_census}C). As a consequence, when examining the mutation coverage across the sequence of the ORF, it is clearly visible that the share of amino acids reachable with a single nucleotide change from the respective wildtype codon is much closer to saturation than the the set of all possible amino acid changes (Figure~\ref{fig:popcode_census}D). Additionally some hotspots are visible, in which mutation rate is higher, which is likely due to different hybridization efficiencies of oligos across the ORF sequence.

Using the Biomatrix robot, we re-arrayed the subset of usable clones into a condensed final library of 40 plates. This final library comprised 6,553 \gene{UBE2I} variants, covering different combinations of 1,848 (61\% of all possible) unique amino acid changes. In preparation for the next stage, variant plasmids were pooled, together with barcoded empty vector and wild type control plasmids.



\subsubsection{Complementation screen and Barcode sequencing}

For Stage 3 of the DMS-BarSeq framework---the selection of clones encoding a functional protein---we employed a previously described \species{S.~cerevisiae} functional complementation assay~\cite{lee_complementation_1987,osborn_rescuing_2007}. This assay is based a yeast strain carrying a temperature sensitive (ts) allele of the \gene{UBE2I} orthologue \gene{UBC9}. Expression of human \gene{UBE2I} rescues growth at an otherwise lethal elevated temperature. As such, the fitness observed for a clone carrying a mutant allele of \gene{UBE2I} can be interpreted as the overall ability of the variant protein to function within its biological context~\cite{sun_extended_2016}. 
The plasmid library from Stage 3 was introduced into the appropriate ts strain by en-masse transformation. Pools were then grown in triplicates over a period of 48 hours at the permissive (25\celsius ) and selective (37\celsius ) temperatures, respectively (see Online Methods) and evaluated at multiple time points via high-throughput sequencing.

To facilitate the readout of the selection (Stage 4), I developed a sequence analysis pipeline. The pipeline distributes sets of read pairs across across the nodes of a high-performance computing cluster, where a k-mer search algorithm is used to identify multiplexing tags that encode the temperature and time point and replicate number associated with the sample. The same algorithm is also used to identify the barcode itself. The number of occurrences of each barcode in each sample is counted and aggregated across the cluster nodes. The frequencies at which each barcode is observed corresponds to the population size of the associated clone. This can then be used to reconstruct of individual growth curves and quantify the normalized fitness for each of the 6,553 strains. The fitness measurements are normalized to the wildtype and null controls, such that a score of 1 is equivalent to the average wildtype fitness, and 0 is equivalent to the average null control fitness.

Additional care needs to be taken to quantify the level of confidence for each fitness measurement. While comparing the three technical replicates available for each clone allows for a rough estimation of standard error, improvements can be made. Baldi and Long previously published a Bayesian method allowing for the regularization of variance estimations using prior data~\cite{baldi_bayesian_2001}. Two sources of prior information offer themselves: (1) A low number of reads counted at time 0 of the experiment which is likely to result in a poor frequency estimate; and (2) the fitness estimate itself, as variance is often proportional to the mean. Indeed, when comparing both properties with the standard deviation, a clear trend is visible (Figure~\ref{fig:baldiLong}). After obtaining a prior estimate via linear regression, it can be used to regularize the empirical standard deviation.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{img/baldi_long.pdf}
	\caption{Comparison of fitness and initial barcode count against standard deviation. Both properties can be used as prior information to improve confidence quantification.}
	\label{fig:baldiLong}
\end{figure}


\subsubsection{A barcoded-based functional map of UBE2I}

Before further refinement in Stages 5 and 6, we wished to assess the quality of complementation scores. We first examined reproducibility of scores between technical replicates (Figure~\ref{fig:barseqValidation}A), and biological replicates (different clones carrying the same mutation; Figure~\ref{fig:barseqValidation}B).  In each case the scores were reproducible (Pearson's R of 0.97 and 0.78, respectively). We next carried out semi-quantitative manual complementation spotting assays for a subset of mutants that spanned the range of fitness scores. Complementation scores from deep mutational scanning correlated well with these small-scale tests. Indeed, agreement between the large-scale and manual scores was about the same as agreement between internal replicates of the large-scale scores (Figure~\ref{fig:barseqValidation}B,C). 

As a further sanity check, we next examined evolutionary conservation and common predictors of deleteriousness, such as PolyPhen-2~\cite{adzhubei_predicting_2001} and PROVEAN~\cite{choi_predicting_2012}.  Although each of these measures is far from perfect in predicting the functionality of amino acid changes, they should and did each correlate with functionality (Figure~\ref{fig:barseqValidation}D,E,F). Finally, we confirmed that, as expected, amino acid residues on the protein surface are more tolerant to mutation than those in the protein core or within interaction interfaces (Figure~\ref{fig:barseqValidation}G).  Taken together, these observations support the biological relevance of the DMS-BarSeq approach.

\begin{landscape}
\begin{figure}
	\centering
	\includegraphics[width=9in]{img/barseq-validation.pdf}
	\caption{Validation of DMS-BarSeq of UBE2I. A: Correlation between technical replicates B: Correlation between biological replicates. C: Manual complementation spotting assay compared to DMS fitness measurements. D: Comparison of fitness levels for mutations at positions with low, medium and high evolutionary conservation. E:Comparison of fitness levels for mutations at positions within the hydrophobic core, at interaction interfaces, and unused surfaces}
	\label{fig:barseqValidation}
\end{figure}
\end{landscape}


\subsection{An alternative strategy for DMS via tiled regional sequencing}

While the DMS-BarSeq approach has many advantages (see Discussion), its performance comes at the cost of producing and maintaining an arrayed clone library, and of determining the full-length sequence of each coding region and barcode for each clone. We therefore investigated an alternative approach called DMS-TileSeq: Instead of tracking the fitness of each individual clone, we carried out \textit{en masse} measurements of the frequency of each variant in the pool before and after selection, by deep sequencing.  Sequencing was carried out for a set of short amplicon tiles that collectively encompass the complete coding region.  In this way, we can discern the impact of each mutation by observing the impact of selection on the abundance of clones carrying this mutation.

In terms of mutagenesis (Stage 1), DMS-TileSeq is identical to DMS-BarSeq.  Given the mutagenized amplicon library, the cloning step (Stage 2) was carried out by \textit{en~masse} recombinational subcloning into complementation vectors (thus skipping the step of arraying and sequencing individual clones).  This plasmid pool was next transformed \textit{en~masse} into the \textit{ubc9-ts} strain appropriate for assessing the complementation ability of \gene{UBE2I} variants. As with DMS-BarSeq, DMS-TileSeq employs pooled strains grown competitively (Stage 3) at the permissive and selective temperatures. However, instead of using barcode sequencing to determine the fitness associated with individual stains, we directly sequence the coding region from the clone population to determine the frequency of each variant in each pool (before and after selection). To overcome the problem of distinguishing mutations from sequencing errors, we divide the coding region into tiles such that each individual template molecule can be completely sequenced on both strands.  By requiring that each variant be seen on both strands, the incidence of base-calling errors can be substantially reduced. %pipeline?

An important aspect of DMS-TileSeq is that it requires the library to be sufficiently complex to ensure that the effect of a mutation is determined from enough clones and averaged over enough genetic backgrounds to be reproducible. Therefore we considered it necessary to first validate the reliability of DMS-TileSeq in comparison to DMS-BarSeq on our established UBE2I map. Correlation between DMS-TileSeq and DMS-BarSeq was comparable to the correlation observed between biological replicates of DMS-BarSeq (Figure~\ref{fig:barVtile}A), suggesting that reproducibility of DMS-TileSeq is at least comparable to that of DMS-BarSeq. DMS-TileSeq and DMS-BarSeq showed comparable agreement with complementation scores from manual assays (Figure~\ref{fig:barVtile}B). Thus, DMS-TileSeq avoids the substantial cost of arraying and sequencing thousands of individual clones, while performing on par with DMS-BarSeq in terms of reliability of the functional complementation scores it produces.

\begin{figure}[h!]
	\centering
	\includegraphics[width=.9\textwidth]{img/barVtile.pdf}
	\caption{Comparison of DMS-BarSeq to DMS-TileSeq scores. A) Scatterplot of functional scores for variants in obtained from BarSeq and TileSeq (transformed to the same scale), whisker bars show regularized standard error. B) Comparison of BarSeq (top) and TileSeq (bottom) scores to manual complementation spotting assay scores (jittered for visibility). Whisker bars show regularized standard error}
	\label{fig:barVtile}
\end{figure}

\subsection{A complete functional map of UBE2I}

Having performed two independent deep mutational scans of UBE2I using functional complementation assays, we wished to integrate both results into a single comprehensive high-quality map. To accomplish this, we first combined the results of each screening approach into a joint map.  This required bringing the maps onto the same scale. Using a regression-based transformation function, we transformed the DMS-TileSeq scores to the more intuitive scale of DMS-BarSeq (where 0 corresponds to the typical score of a null mutant and 1 corresponds to the typical score of a wildtype control). We then combined scores from the two methods, giving greater weight to more confident measurements (see methods section).

\subsubsection{Imputation and regularization of missing or less accurate data}

As is the case for all previously published DMS maps, our combined map contained some entries that were poorly measured or missing (e.g., because these substitutions were underrepresented in the input clone library). To fill the gaps in the map (Stage 5 in the framework), we trained a Random~Forest~\cite{breiman_random_2001} regression model using the existing measurements in the map. The features used for the model fall into four categories: intrinsic information; conservation information; chemicophysical properties; and structural properties. 

The most important intrinsic feature consists of weighted positional averages in the map. That is, for any given amino acid change, we weight all other observed effects of variants at the same amino acid position by their measurement confidence and form the average. A second intrinsic feature consists of the confidence-weighted average effect of all variants containing the amino acid change in question. Finally, as a third intrinsic feature we calculate the expected variant fitness predicted by a multiplicative model often applied to detect genetic interactions~\cite{phillips_language_1998,onge_systematic_2007}. In the absence of interaction, the fitness of a double mutant $f_{A,B}$ is expected to follow the product of the individual single mutant fitness levels $f_{A,B}\approx f_A \cdot f_B$. Thus, in cases where a double mutant $(A,B)$ and a single mutant $B$ is known, we can estimate the fitness of $A$ to be $f_A\approx \frac{f_{A,B}}{f_B}$. The model is applied to all available double mutant fitness values carrying the mutation in question in combination with available complementary single mutant fitness values. As the latter two features rely on multi-mutant fitness measurements, they can only be applied where DMS-BarSeq data is available. 

The second category of features focuses on evolutionary conservation. For each amino acid change in question this encompasses the corresponding BLOSUM62~\cite{henikoff_amino_1992}, SIFT~\cite{ng_predicting_2001} and PROVEAN~\cite{choi_predicting_2012} scores, and the AMAS~\cite{livingstone_protein_1993} conservation at the given position. The third category of features comprises chemicophysical properties such as mass and hydrophobicity of  the original and wildtype amino acids and the difference between the two. The fourth and final category of features consisted of structural properties of the affected amino acid residues, such as solvent accessibility and burial in interaction interfaces.

\begin{landscape}
\begin{figure}[h]
	\centering
	\includegraphics[width=9in]{img/imputation.pdf}
	\caption{Evaluation of machine learning imputation. A) Cross-validation correlation between measured values and machine learning predictions. B) Cross validation prediction error landscape. C) Manual complementation spotting assay compared to machine learning predictions for an independent test set of variants not present in the training data. D) Feature importance as measured by average increase in mean squared error.}
	\label{fig:imputation}
\end{figure}
\end{landscape}

We assessed the performance of the imputation model using cross-validation. Surprisingly, we found the root-mean-squared deviation (RMSD) of imputed values to be on par with measurement error in experimentally measured data (Figure~\ref{fig:imputation}A). An examination of the prediction performance by location showed increased error in positions with lower mutation density and for variants with in above-WT fitness levels (Figure~\ref{fig:imputation}B). As an additional validation step, we performed manual complementation assays for a set of UBE2I variants that were not present in the machine learning training data set and compared the results against the predictions (Figure~\ref{fig:imputation}C), again finding a surprisingly strong agreement. Notably, variants showing above wild-type level growth in the manual assay were generally predicted to be deleterious. Although above-WT complementation may indicate that a variant is adaptive in yeast, the imputation models suggested that these variants would be deleterious in humans, a hypothesis we explore further in chapter~\ref{ch:data2}. 


An analysis of feature importance can be performed by comparing the increase in means squared prediction error upon permuting the values of a feature in question. The analysis revealed that intrinsic features were the most informative (Figure~\ref{fig:imputation}D), with the weighed position-wise average and multi-mutant average seen to be the two single most important features (49\% and 40\%, respectively), while the multiplicative model contributed 14\%. The second most important group was conservation information, with PROVEAN and SIFT weighing in at 39\% and 32\%, respectively.

\begin{figure}[h!]
	\centering
	\includegraphics[width=.6\textwidth]{img/regularization_spotting.pdf}
	\caption{Left: Comparison of values in the regularized map against manual complementation spotting assay values. Right: Completeness of the map (in terms of coverage of possible amino acid changes) at different stages of the framework.}
	\label{fig:regularization}
\end{figure}

Finally, in stage 6 of the DMS framework, we wished to address cases in which experimental measurements were available but less confident. We employed a regularization method, combining experimental measurements with machine-learning predicted values after dynamically weighting them according to their respective confidence levels. That means: the less confident a measurement, the stronger the regularization. 
To evaluate the complete map, we once more applied manual complementation assays to a set of variants that represented the full range of fitness scores.  DMS fitness scores corresponded closely with manual assays (Figure~\ref{fig:regularization}), thus validating our framework. 


%\todo{At this point it would be nice to show off the value of the regularization, but for the unflipped UBE2I map it doesn't improve anything. The flipped maps, especially for TPK1 and CALM1 benefit much more from regularization. It would also be great if we could point to the spotting assay, but we didn't test any poorly measured clones, so we don't have any interesting data there.}

\section{Discussion}

Here we have demonstrated the capabilities of a new improved Deep Mutational Scanning framework that uses functional complementation in yeast to map the impact of mutations on the overall ability of a protein to function. We integrated a machine learning-based imputation and regularization strategy into the deep mutational scanning process, to create the first DMS maps that are complete with respect to high-quality functional impact scores over the full length of a protein.

The two versions of DMS we described, DMS-BarSeq and DMS-TileSeq, each have advantages and limitations. DMS-BarSeq permits study of the combined effects of mutations located at any distance along the clone, and therefore can reveal intramolecular genetic interactions.  Mutant clones produced for DMS-BarSeq are arrayed, sequenced and indexed which can enable follow up investigation of individual variants. DMS-BarSeq can directly compare growth of any clone to null and wild type controls, resulting in an intuitive scoring scheme. However, the cost of arraying and sequencing clones for DMS-BarSeq renders it more costly and labour intensive, even given the efficient KiloSeq strategy. By contrast, the regional sequencing strategy of DMS-TileSeq is substantially more efficient, but can only analyze fitness of those double mutant combinations that fall within the same tile. 

The use of codon-replacement mutagenesis allowed us to observe a fuller repertoire of amino-acid substitutions than single-nucleotide mutagenesis would have allowed (only $\sim~30\%$ of all possible amino acid substitutions are accessible by single nucleotide mutation).  However, given that the majority of missense variants observed on individual genome are single-nucleotide variants~\cite{lek_analysis_2016}, one might reasonably wonder whether codon mutagenesis is worth carrying out in addition to single-nucleotide mutagenesis.  We see three arguments for using codon-level mutagenesis to reveal the impact of all 19 possible amino acid substitutions at each position:  1) a full picture of functional missense variation enables a clearer understanding of what biochemical properties required of each functionally important residue; 2) an analysis of over 60,000 unphased human exomes~\cite{lek_analysis_2016} found that each individual human harbors approximately 23 codons containing multiple nucleotide variants that collectively encode an amino acid not encoded by either single variant; 3) it seems likely that, going forward, the dominant cost of DMS will be development and validation of the functional assay, so that carrying out codon-level mutagenesis instead of (or in addition to) nucleotide-level mutagenesis has a relatively small impact on overall cost.


\section{Methods}

\subsection{Mutagenesis and library construction}

\paragraph{Oxidized nucleotide PCR: } Oxidized nucleotide PCR was performed by Jennifer Knapp as previously described by Mohan and colleagues~\cite{mohan_pcr_2011}. Primers were designed to attach attB sites to the product in preparation for Gateway cloning.

\paragraph{POPCode:} POPCode oligos are generated using the POPCodeSuite webtool I created. Given a target oligo length and a maximum length offset, the tool calculates for every codon in the target gene the set of possible oligos conforming to the length and offset parameters. Then, melting temperatures for the 5' and 3' halves of each oligo are calculated. For each codon, the oligo that most closely matches the median 5' and 3' melting temperatures is chosen. Based on parameters derived previous observations, the expected mutation frequency is calculated for each oligo and used to simulate variant coverage rates at different library sizes. The source code is provided on the attached storage media and can also be found online\footnote{
\url{http://dalai.mshri.on.ca/~jweile/projects/popcodeSuite/}
}.

POPCode mutagenesis was performed by Atina Cote, Jennifer Knapp and Marta Verby in the following steps: (i) A uracil-containing wild type template was generated by PCR-amplifying the ORF in the presence of dUTP, (ii) pooled oligonucleotides were hybridized with the template and gaps between hybridized oligonucleotides were filled with the non-strand-displacing Sulpholobus Polymerase IV (NEB) or Kapa HiFi Uracil+ DNA polymerase (KapaBiosystems) and sealed with T4 DNA ligase (NEB), (iii) the uracil-doped wild-type template was then degraded using Uracil-DNA-Glycosylase (UDG) (NEB) and the mutagenesis product was amplified with attB-sites-containing primers to allow the downstream Gateway BP cloning.

\paragraph{Library construction:} Library construction was performed by Atina Cote, Jennifer Knapp and Marta Verby. Pooled mutagenesis product carrying attB sites is cloned in to barcoded expression pHYC expression vectors in en-masse Gateway BP and LR reactions and subsequently transformed into E.coli. Automated colony picking using a BioMatrix robot was used to array $\sim$10,000 clones.

\subsection{KiloSeq and library condensation}

KiloSeq library preparation was performed by Atina Cote, Jennifer Knapp and Marta Verby. 384-well plates are prepared with PCR mastermix, where each well contains differently tagged oligos representative its respective well coordinate. A BioMatrix robot is used to stamp clones directly from the library plates into the wells. Colony PCR is performed directly in the plates using a HydroCycler. Wells across each plate are then pooled and fragmented using Nextera Tn5 tagmentation. Fragments carrying the well-specific tags within each pool are then re-amplified using primers carrying Illumina i5/i7 linkers with plate-specific indices. Finally, the products are pooled, purified and size selected.


\begin{figure}[h!]
	\centering
	\includegraphics[width=.6\textwidth]{img/kiloseq_pipeline.pdf}
	\caption{KiloSeq analysis pipeline: \texttt{bcl2fastq} is used to demultiplex by plate. The resulting FASTQ files are broken up in to chunks and feed to worker nodes on the fly. Each worker identifies well-tags in the R2 reads and demultiplexes by well accordingly. After demultiplexing is complete, jobs for each well in each plate are distributed across worker nodes. There, barcode sequences are extracted and clustered based on Levenshein distance. R1 reads from each cluster are aligned to the ORF reference and pileups are generated, which are used for variant calling and long indel detection (via recognition of sudden changes in read depth using a modified Sobel filter.)}
	\label{fig:kiloseqPipeline}
\end{figure}


Sequencing data is processed using a custom pipeline I developed that runs on a high-performance computing cluster (Figure~\ref{fig:kiloseqPipeline}). The source code is provided on the attached storage media and can also be found online\footnote{\url{http://dalai.mshri.on.ca/~jweile/projects/kiloseq/}}.

After identification of desirable clones using KiloSeq, the selected clones were condensed into a smaller library using the BioMatrix Robot. I created a custom software library to automatically program the BioMatrix Robot's picking protocol. It is provided on the attached storage media and can also be found online\footnote{\url{http://dalai.mshri.on.ca/~jweile/projects/biomatrix/}}.

\subsection{DMS-BarSeq}

\paragraph{Complementation competition experiment:} Complementation experiments were performed by Jennifer Knapp, Song Sun and Marta Verby. After pooling the barcoded \gene{UBE2I} variant library it was transformed \textit{en masse} together with barcoded null and wildtype controls into an \species{S. cerevisiae} \textit{ubc9-ts} strain. 
The pool was grown in triplicates on solid media at 25\celsius\ and 37\celsius\ to be examined at 5 different timepoints (0h, 6h, 12h, 24h, 48h), which required a total of 30 plates. At their respective timepoints, plates were scraped, OD quantified, and their barcode loci amplified with primers carrying sample-specific tags. The amplified product is then sequenced on an Illumina NextSeq 500.

\paragraph{Sequence analysis:} I created a custom sequence analysis pipeline, which was used to identify and count individual sample tags and barcode combinations within each read. The pipeline source code is provided on the attached storage media and can also be found online\footnote{\url{http://dalai.mshri.on.ca/~jweile/projects/screen_pipeline/}}.

\paragraph{Scoring:} I developed a custom software to perform scoring and statistical analysis. First, the relative population size for each clone is calculated by dividing each clone's barcode count by the total number of barcodes in each condition. Then the estimated absolute population size for each clone is calculated by multiplying the relative population size with the estimated total number of cells on the respective plate at the corresponding time point (obtained from OD measurements). We then treat the amount of growth between each individual time point compared to the pool average as an individual estimate of fitness, all of which act cumulatively. This is calculated as follows: Let $c_{i,t_k}^\tau$ be the barcode count for clone $i$, timepoint $t_k$ at temperature $\tau$, then $ \forall i \in \{1 \le i \le N | i \in \mathbb{N} \}$, 
$\forall k \in \{1 \le k \le 5 | k \in \mathbb{N} \}$, 
$\forall \tau \in \{25^{\circ},37^{\circ} \}$

\begin{align*}
r_{i,t_k}^{(\tau)} &= \frac{ c_{i,t_k}^{(\tau)} }{ \sum_j c_{j,t_k}^{(\tau)} }\\
P_{i,t_k}^{(\tau)} &= r_{i,t_k}^{(\tau)} \cdot P_{*,t_k}^{(\tau)} \\
\rho_{i,t_k}^{(\tau)} &= \sqrt[\uproot{5}(t_k - t_{k-1})]{\frac{P_{i,t_k}^{(\tau)}}{P_{i,t_{k-1}}^{(\tau)}}} \\
%\rho_{*,t_k}^\tau &= \sqrt[\uproot{5}(t_k - t_{k-1})]{\frac{P_{*,t_k}^\tau}{P_{*,t_{k-1}}^\tau}} \\
\phi_{i,t_k}^{(\tau)} &= \frac{\rho_{i,t_k}^{(\tau)}}{\rho_{*,t_k}^{(\tau)}}\\
\phi_{i,t_k}^\prime &= \frac{\phi_{i,t_k}^{(37^{\circ})}}{\phi_{*,t_k}^{(25^{\circ})}}\\
s_i &= \prod_k \phi_{i,t_k}^\prime \\
s'_i &= \frac{s_i - s_\text{null}}{s_\text{wt} - s_\text{null}},
\end{align*}

where $r_{i,t_k}^{(\tau)}$ is the relative population size for clone $i$ and timepoint $t_k$ at temperature $\tau$, $P_{i,t_k}^{(\tau)}$ is the absolute population size for clone $i$, timepoint $t_k$ at temperature $\tau$, $\rho_{i,t_k}^{(\tau)}$ is the measured hourly growth rate for clone $i$, timepoint $t_k$ at temperature $\tau$, $\phi_{i,t_k}^{(\tau)}$ is the fitness advantage relative to the pool growth for clone $i$, timepoint $t_k$ at temperature $\tau$, $\phi_{i,t_k}^\prime$ is the normalized relative fitness advantage for clone $i$ at timepoint $t_k$, and $s_i$ is the cumulative normalized relative fitness advantage for clone $i$. Finally, $s'_i$ is the fitness score relative to the internal null and wild type controls. This results in null-like mutants receiving a score of zero and wild type-like mutants receiving a score of one.

The scoring software is part of a larger DMS analysis package provided on the attached storage media. It is also available online\footnote{\url{http://dalai.mshri.on.ca/~jweile/projects/popcodePipeline/doc}}.

\paragraph{Error regularization: } Standard error measurements for each clone were regularized using a Bayesian method published by Baldi and Long~\cite{baldi_bayesian_2001}. A prior estimate for each measurement was obtained via linear regression over permissive read counts and fitness values. The prior is combined with the empirical standard deviation obtained from technical replication using Baldi and Long's original formula $$\sigma^2 = \frac{v_n \sigma_n^2}{v_n - 2} = \frac{v_0 \sigma_0^2 + (n-1)s^2}{v_0 + n - 2},$$ where $v_0$ represents the degrees of freedom assigned to the prior estimate, $\sigma_0$ is the prior estimate, $n$ represents the degrees of freedom for the empirical data (i.e. the number of replicates) and $s$ is the empirical standard deviation.

The error regularization procedure is part of a larger DMS analysis package provided on the attached storage media. It is also available online\footnote{\url{http://dalai.mshri.on.ca/~jweile/projects/popcodePipeline/doc}}.


\subsection{DMS-TileSeq}

\paragraph{Complementation competition experiment} 
The complementation experiment was performed by Song Sun and Marta Verby in much the same way as for DMS-TileSeq, but only in duplicates rather than triplicates and only a single 48h timepoint.

\paragraph{TileSeq Sequencing:} Oligos were designed to evenly distribute across the sequence of the \gene{UBE2I} ORF in 60bp intervals and used to amplify individual sequence tiles. The resulting product was used in paired-end sequencing. A custom script was used to align reads to the \gene{UBE2I} template to identify and count variants detected by both reads in each pair. Mutation counts in each condition are normalized to sequencing depth at the respective position. Then, wildtype control counts are subtracted from the selective and permissive condition counts. Finally, the log ratio between adjusted selective and permissive counts is calculated. Error regularization was performed the same way as in DMS-BarSeq. 
The scoring procedure is implemented as part of a larger DMS analysis package provided on the attached storage media. It is also available online\footnote{\url{http://dalai.mshri.on.ca/~jweile/projects/popcodePipeline/doc}}.

\subsection{Joining of maps, imputation and regularization}

While DMS-TileSeq produces only one fitness score per variant, DMS-BarSeq in many cases contains multiple biological replicates of the same variant associated with different barcodes. To provide summary fitness values on a per-variant basis, scores from biological replicates were combined using weighted means, where the weight is inversely proportional to the Bayesian regularized standard error. The standard error associated with the joint score is also adjusted to account for differences in input fitness measurements and increased sample size.
The results from the barcoded and regional sequencing screens do not scale linearly with each other. We used regression to find a monotonic transformation function $$f(x) = a \cdot e^x + b \cdot x + c$$ between the two screens' respective scales. The standard deviation is transformed accordingly using a Taylor series-based approximation. $$ \sigma' = \sigma \cdot (a\cdot e^{\mu} + b)  $$ After both datasets have been brought to the same scale we can join corresponding data points using weighted means, where the weight is again inversely proportional to the Bayesian regularized standard error. Output standard error was adjusted again to account for differences in input fitness values and increased sample size. 
\begin{align*}
w_0 &= \frac{1}{1+\frac{\sigma_{\bar x}^{(0)}}{\sigma_{\bar x}^{(1)}}}; ~ w_1 = \frac{1}{1+\frac{\sigma_{\bar x}^{(1)}}{\sigma_{\bar x}^{(0)}}}\\
\mu_\text{joint} &= w_0 \cdot \mu_0 + w_1 \cdot \mu_1\\
\sigma_\text{joint}^2 &= w_0 \cdot (\sigma_0^2 + \mu_0^2) + w_1 \cdot (\sigma_1^2 + \mu_1^2) - \mu_\text{joint}^2\\
\sigma_{\bar x}^{(\text{joint})} &= \frac{\sigma_\text{joint}}{\sqrt{df_0 + df_1}}
\end{align*}
where $\mu_0$ is the DMS-BarSeq value, $\sigma_0$ the associated standard deviation, $\sigma_{\bar x}^{(0)}$ the associated standard error, $df_0$ the associated degrees of freedom, $\mu_1$ is the DMS-TileSeq value, $\sigma_1$ the associated standard deviation, $\sigma_{\bar x}^{(1)}$ the associated standard error, and $df_1$ the associated degrees of freedom.

Imputation of missing values was performed using \texttt{RandomForest} Regression~\cite{breiman_random_2001}. The following intrinsic features were generated: the confidence-weighted average fitness across mutations at the same position; the average fitness of multi-mutant clones that contain the mutation of interest; and the estimated fitness according to a multiplicative model to infer mutant fitness A using a double mutant AB and single mutant B.
A second set of features was computed from differences between various chemical properties of the wildtype and mutant amino acids. These properties include size, volume, polarity, charge, and hydropathy.
A third set of features is derived from the structural context of each amino acid position. These include secondary structure, solvent accessibility, burial in interfaces with different interaction partners, and involvement in hydrogen bonds or salt bridges with interaction partners. Secondary structures were calculated using \texttt{Stride}~\cite{frishman_knowledge-based_1995}. Solvent accessibility and interface burial were calculated using the \texttt{GETAREA} tool~\cite{fraczkiewicz_exact_1998} on the following PDB entries: \texttt{3UIP}~\cite{gareau_determinants_2012}; \texttt{4W5V}~\cite{reiter_characterization_2016}; \texttt{3KYD}~\cite{olsen_active_2010}; \texttt{2UYZ}~\cite{knipscheer_noncovalent_2007}; \texttt{4Y1L}~\cite{alontaga_rwd_2015}. Hydrogen bonds and salt bridges candidates were predicted using \texttt{OpenPyMol}~\cite{schrodinger_pymol_2016} and evaluated for validity by manual inspection.
Additional features used are the PROVEAN~\cite{choi_predicting_2012} and BLOSUM~\cite{henikoff_amino_1992} scores for a given amino acid change and the evolutionary conservation of the amino acid position. Conservation was obtained by generating a multiple alignment of direct functional orthologues across many eukaryotic species using \texttt{CLUSTAL}~\cite{russell_clustal_2014}, which was used as input for \texttt{AMAS}~\cite{livingstone_protein_1993}.

The machine learning predictions resulting generated above were also used to regularize experimental measurements of lower confidence. To this end, the corrected standard error associated with each data point can be used to determine the weight assigned to the measurement, as follows:
 
\begin{align*}
w_0 &= \frac{1}{1+\frac{\sigma_{\bar x}^{(0)}}{\sigma_{\bar x}^{(1)}}}; ~ w_1 = \frac{1}{1+\frac{\sigma_{\bar x}^{(1)}}{\sigma_{\bar x}^{(0)}}}\\
\mu_\text{joint} &= w_0 \cdot \mu_0 + w_1 \cdot \mu_1\\
\sigma_\text{joint}^2 &= w_0 \cdot (\sigma_0^2 + \mu_0^2) + w_1 \cdot (\sigma_1^2 + \mu_1^2) - \mu_\text{joint}^2\\
\sigma_{\bar x}^{(\text{joint})} &= \frac{\sigma_\text{joint}}{\sqrt{df_0 + df_1}}
\end{align*}
where $\mu_0$ is the measured value, $\sigma_0$ the associated standard deviation, $\sigma_{\bar x}^{(0)}$ the associated standard error, $df_0$ the associated degrees of freedom, $\mu_1$ is the RandomForest predicted value, $\sigma_1$ the associated standard deviation as approximated by cross-validation RMSD, $\sigma_{\bar x}^{(1)}$ the associated standard error, and $df_1$ the associated virtual degrees of freedom.

The joining, imputation, and regularization procedures are implemented as part of a larger DMS analysis package provided on the attached storage media, and also available online\footnote{\url{http://dalai.mshri.on.ca/~jweile/projects/popcodePipeline/doc}}.

\subsection{Complementation spotting assays}
To validate the reliability of the fitness scores obtained during the screen, we selected a subset of clones from our original variant library that evenly covered the spectrum of scores present in the screen. After genotype verification using Sanger sequencing, \species{S. cerevisiae} \textit{ubc9-ts} strains were transformed, grown to saturation, spotted in 1/5 dilution steps, and grown at the permissive and selective temperatures respectively for 48 hours in the presence of null and wildtype control. The laboratory procedures were performed by Jennifer Knapp. I developed a custom software, PlateOrganizer, to organize and analyze image data from spotting assays. It is provided on the attached storage media and can also be found online\footnote{\url{http://dalai.mshri.on.ca/~jweile/projects/PlateOrganizer/}}.

